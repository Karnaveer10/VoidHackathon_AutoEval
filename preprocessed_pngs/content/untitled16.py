# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W5ka7JIbkjQ7F57cmxVD2JXli1Bqvk14
"""





!pip install opencv-python pytesseract pandas

import cv2
import numpy as np

img = cv2.imread('/content/1_aug_1.jpg')  # Change path
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Apply median filter for salt-and-pepper noise
median = cv2.medianBlur(gray, 3)

# Gaussian blur for smoother noise removal
gauss = cv2.GaussianBlur(median, (5,5), 0)

import matplotlib.pyplot as plt

plt.imshow(gauss, cmap='gray')  # Show grayscale image
plt.title('My Image')
plt.axis('off')
plt.show()

import matplotlib.pyplot as plt

plt.imshow(contrasted, cmap='gray')  # Show grayscale image
plt.title('My Image')
plt.axis('off')
plt.show()

# Apply CLAHE for local contrast enhancement
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
contrasted = clahe.apply(gauss)

thresh = cv2.adaptiveThreshold(contrasted, 255,
                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                               cv2.THRESH_BINARY, 11, 2)

import cv2
import numpy as np

# Compute the text/line orientation from deskewing
coords = np.column_stack(np.where(thresh > 0))
angle = cv2.minAreaRect(coords)[-1]
if angle < -45:
    angle = -(90 + angle)
else:
    angle = -angle

(h, w) = thresh.shape
center = (w // 2, h // 2)
M = cv2.getRotationMatrix2D(center, angle, 1.0)
deskewed = cv2.warpAffine(thresh, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)

# Now, explicitly check orientation by analysing aspect ratio AND line directions
# Calculate horizontal/vertical line densities
edges = cv2.Canny(deskewed, 50, 150, apertureSize=3)
lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=100, maxLineGap=10)

horizontal = 0
vertical = 0
for line in lines:
    x1, y1, x2, y2 = line[0]
    if abs(x2 - x1) > abs(y2 - y1):  # Horizontal line
        horizontal += 1
    else:  # Vertical line
        vertical += 1

# If there are more horizontal lines, rotate to portrait
if horizontal > vertical and deskewed.shape[1] > deskewed.shape[0]:
    deskewed = cv2.rotate(deskewed, cv2.ROTATE_90_CLOCKWISE)

# Final output: always portrait!

import matplotlib.pyplot as plt

plt.imshow(deskewed, cmap='gray')  # Show grayscale image
plt.title('My Image')
plt.axis('off')
plt.show()

import cv2

# If your processed image is called 'deskewed' or 'warped', rotate:
#rotated = cv2.rotate(deskewed, cv2.ROTATE_90_CLOCKWISE)
# or
deskewed = cv2.rotate(deskewed, cv2.ROTATE_90_COUNTERCLOCKWISE)

# Display to check
import matplotlib.pyplot as plt
plt.imshow(rotated, cmap='gray')
plt.title('Final Portrait Image')
plt.axis('off')
plt.show()

peri = cv2.arcLength(contour, True)
corners = cv2.approxPolyDP(contour, 0.02 * peri, True)

# Check if we really got 4 corners
if len(corners) == 4:
    corners = corners.reshape(4, 2)
    # proceed with perspective transform
else:
    print(f"Contour did not have 4 points! Found: {len(corners)}")
    # Optional: Use boundingRect as fallback
    x, y, w, h = cv2.boundingRect(contour)
    corners = np.array([
        [x, y],
        [x + w, y],
        [x + w, y + h],
        [x, y + h]
    ], dtype='float32')
    # Now proceed!

def order_points(pts):
    # pts: (4,2) array of corner coordinates
    s = pts.sum(axis=1)
    diff = np.diff(pts, axis=1)
    ordered = np.zeros((4, 2), dtype='float32')
    ordered[0] = pts[np.argmin(s)]      # top-left
    ordered[2] = pts[np.argmax(s)]      # bottom-right
    ordered[1] = pts[np.argmin(diff)]   # top-right
    ordered[3] = pts[np.argmax(diff)]   # bottom-left
    return ordered
ordered_corners = order_points(corners)

import cv2

# Load your ideal template image
template = cv2.imread('/content/1.jpg')  # Replace with your template's path

# Get dimensions (Note: OpenCV reads as [height, width, channels])
h, w = template.shape[:2]
print("Template width:", w)
print("Template height:", h)

w = 1700  # Set desired width of output (template)
h = 2200  # Set desired height (template)

dst = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype='float32')
M = cv2.getPerspectiveTransform(ordered_corners, dst)
warped = cv2.warpPerspective(deskewed, M, (w, h))

# Find bounding box of the nonzero regions
coords2 = np.column_stack(np.where(warped > 0))
ymin, xmin = coords2.min(axis=0)
ymax, xmax = coords2.max(axis=0)
cropped = warped[ymin:ymax, xmin:xmax]

mask = (cropped == 0).astype(np.uint8)  # Assume white=0 is missing regions
inpainted = cv2.inpaint(cropped, mask, 3, cv2.INPAINT_TELEA)

import matplotlib.pyplot as plt

plt.imshow(inpainted, cmap='gray')  # Show grayscale image
plt.title('My Image')
plt.axis('off')
plt.show()

import cv2
import matplotlib.pyplot as plt

# Assume your image is named 'inpainted'
color_img = cv2.cvtColor(inpainted, cv2.COLOR_GRAY2BGR)

# Now display with matplotlib for quick viewing
plt.imshow(cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB))
plt.title('Coloured Output Image')
plt.axis('off')
plt.show()

import cv2
img = cv2.imread("/content/1_aug_1.jpg")   # Load coloured image
denoised = cv2.medianBlur(img, 3)  # Apply median blur to all channels
# May slightly reduce sharpness; preserves color

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load your colored answer sheet image
img = cv2.imread('/content/1_aug_1.jpg')

# Convert to grayscale for edge detection
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Optionally blur to reduce noise
blurred = cv2.GaussianBlur(gray, (5,5), 0)

# Detect edges using Canny
edges = cv2.Canny(blurred, 50, 150, apertureSize=3)

# Find lines using Hough Transform
lines = cv2.HoughLines(edges, 1, np.pi / 180, 150)  # 150 is threshold: adjust as needed

# Collect angles of all detected lines
angles = []
if lines is not None:
    for i in range(len(lines)):
        rho, theta = lines[i][0]
        angle = (theta * 180 / np.pi)
        # Keep horizontal and near-horizontal lines only (if that's relevant for your form)
        if angle < 10 or angle > 170:
            angles.append(angle)
        elif 80 < angle < 100:
            angles.append(angle)  # Optional: include verticals

    # Compute the median angle for robust estimation
    median_angle = np.median(angles)
    # Subtract 90 to switch from Hough angle to image rotation
    skew_angle = median_angle - 90

    h, w = img.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, skew_angle, 1.0)
    deskewed = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
else:
    print("No lines detected! Returning original image.")
    deskewed = img

# Display the deskewed color image
plt.imshow(cv2.cvtColor(deskewed, cv2.COLOR_BGR2RGB))
plt.title(f"Deskewed (Angle: {skew_angle:.2f}°)")
plt.axis('off')
plt.show()

import cv2

# Read the JPG image
img = cv2.imread('input.jpg')  # Replace 'input.jpg' with your filename

# Save as PNG
cv2.imwrite('output.png', img)

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
from google.colab import drive

# ===== Optional: Mount Google Drive if images are stored there =====
# drive.mount('/content/drive')

# ===== Define input and output directories =====
input_folder = '/content/input_images'   # Path where your input images are stored
output_folder = '/content/preprocessed_pngs'  # Folder to save processed images

# Create the output folder if it doesn’t exist
os.makedirs(output_folder, exist_ok=True)

# ===== Loop through all image files in the folder =====
for filename in os.listdir(input_folder):
    if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')):
        img_path = os.path.join(input_folder, filename)
        img = cv2.imread(img_path)

        if img is None:
            print(f"Skipping {filename} — unable to read image.")
            continue

        # --- Step 1: Convert to grayscale for edge detection ---
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # --- Step 2: Optionally blur to reduce noise ---
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)

        # --- Step 3: Detect edges using Canny ---
        edges = cv2.Canny(blurred, 50, 150, apertureSize=3)

        # --- Step 4: Find lines using Hough Transform ---
        lines = cv2.HoughLines(edges, 1, np.pi / 180, 150)

        angles = []
        if lines is not None:
            for i in range(len(lines)):
                rho, theta = lines[i][0]
                angle = (theta * 180 / np.pi)
                if angle < 10 or angle > 170:
                    angles.append(angle)
                elif 80 < angle < 100:
                    angles.append(angle)

            if len(angles) > 0:
                median_angle = np.median(angles)
                skew_angle = median_angle - 90

                h, w = img.shape[:2]
                center = (w // 2, h // 2)
                M = cv2.getRotationMatrix2D(center, skew_angle, 1.0)
                deskewed = cv2.warpAffine(img, M, (w, h),
                                          flags=cv2.INTER_CUBIC,
                                          borderMode=cv2.BORDER_REPLICATE)
            else:
                print(f"No valid angles for {filename}. Skipping rotation.")
                deskewed = img
        else:
            print(f"No lines detected in {filename}. Using original image.")
            deskewed = img

        # --- Step 5: Convert and save as PNG ---
        base_name = os.path.splitext(filename)[0]
        output_path = os.path.join(output_folder, base_name + '.png')
        cv2.imwrite(output_path, deskewed)

        print(f"✅ Processed and saved: {output_path}")

print("\nAll images processed and saved in:", output_folder)

# --- (Optional) Display one example image ---
sample_image = os.listdir(output_folder)[0]
sample_path = os.path.join(output_folder, sample_image)
plt.imshow(cv2.cvtColor(cv2.imread(sample_path), cv2.COLOR_BGR2RGB))
plt.title("Sample Deskewed Image")
plt.axis('off')
plt.show()

!zip -r preprocessed_pngs.zip /content/preprocessed_pngs

